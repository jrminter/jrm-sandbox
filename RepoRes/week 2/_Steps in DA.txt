Steps in DA

> I think the key challenge in, in pretty much any data analysis was well characterized by Dan Meyer who's a mathematics educator and he taught high school mathematics. In his Ted talk he said ask yourselves what problem have you solved ever, that was worth solving where you knew all the given information in advance. Where you didn't have a surplus of information and have to filter it out. Or you had insufficient information and had to go find some.

You have to sort though this

Part 1

1. Define the question. Put effort here. Best dimension reduction tool. Be as specific as possible.
2. Define the ideal data set.  Example: Can I detect spam mail? Spam vs Ham. Can I use characteristics of emails to predict spam/ham?  What is the ideal dataset? 
3. Determine what data you can access
4. Obtain the data
5. Clean the data

Part 2
6. Exploratory data analysis
7. Statistical prediction and modeling
8. Interpret the results
9. Challenge the results
10. Synthesize results
11. Create reproducible code


Using kernlab. 58 variables

Split into training and test on another part. Random split rbinom
training vs test
exploratory data analysis look like, relations? summaries, missing data

training: names - all are words. 1st 5 are freqencies of words in ds.

Make some plots of certain characteristic - avg num of capitals. use log transform - add 1 to data to solve log... Spam has more capital letter than non-spam

pairwise plot (log transform)

Explore - cluster analysis. Need to worry about biases...

stat model - informed by exploratory. Uncertainty and sources. Try logistical regression model. look for predictors.
try predictions... Look for cutoff start with 0.5...

capture error rate 22%

Use appropriate language in interpretation. Explanations are helpful along with uncertainty.

Challenge process and analysis...

Synthesis is important - winnow to a coherent report. Focus as a question and summarize. **Coherent story** order fit story, order isn't usual helpful. Well done figures help!!!

Reproducible code - document as you go.


How to organize. One size doesn't fit all. General ideas

Data Raw & process

Figures and tables, final figures. Well annotated

R code: used and unused, final scripts..., rmarkdown, test report...

Raw data - processing, cleaning, ... store raw and processed and provenance. Version control - add raw data if it fits...

Processed data - cleaned. named well... Tidy...

Exploratory figures... Quick looks. Not all incorporated

Final figures - more polished. Journal: typically at most 4-5 annotated well

Lots of scripts. Lots don't make final cut... Stored sep from final

Final scripts - much better commented, cleaned...

Rmarkdown scripts.... Tend to be more final... Readme less useful with Rmd

Text of report title, intro, methods, results, conclusions - get a coherent story and references.
















